# Example configuration for ai-cli-assistant (YAML)
# Non-secret settings are defined here. Secrets must come from environment variables.

# Select the AI backend provider. Currently supported: "openai"
backend: openai

# Influences wording (e.g., "bash", "powershell", "kubectl")
cliKind: cli

# Optional prompt template. If omitted, a sensible default is used.
# The template should contain two %s placeholders: the first for cliKind, the second for the action text.
# Example:
# prompt: |
#   Provide a %s command for the following action: %s.
#   Provide first an example and afterwards a description. Here is an example how the output scheme should look like:
#   Command: <example command>
#
#   Description: <step by step description of the command>

# Maximum number of tokens for the response
maxTokens: 256

# OpenAI backend-specific configuration
openai:
  # Optional: override the default endpoint (e.g., to route via a local proxy)
  # Leave empty to use the default: https://api.openai.com/v1/chat/completions
  endpoint: ""
  # Optional: override the default model (e.g., "gpt-4o-mini", "gpt-3.5-turbo")
  # Leave empty to use the default model.
  model: ""
